graph TB
    %% Data Sources
    subgraph "Pretrained Models"
        A1[XLM-RoBERTa]
        A2[mBART]
        A3[NLLB]
    end
    
    %% Bootstrap Phase
    subgraph "Phase 1: Bootstrap"
        B1[bootstrap_from_pretrained.py<br/>ðŸŽ¯ Initialize Models]
        B2[universal_encoder_initial.pt]
        B3[universal_decoder_initial.pt]
        B4[Vocabulary Mappings]
    end
    
    %% Training Infrastructure
    subgraph "Phase 2: Training Infrastructure"
        C1[distributed_train.py<br/>ðŸ”§ Multi-GPU Setup]
        C2[memory_efficient_training.py<br/>ðŸ”§ Memory Optimization]
    end
    
    %% Main Training - SINGLE SCRIPT
    subgraph "Phase 3: Complete Training"
        D1[train_universal_system.py<br/>ðŸš€ MAIN TRAINING SCRIPT<br/>Complete Implementation]
        D2[Training Loop]
        D3[Validation]
        D4[Checkpointing]
        D5[Logging]
    end
    
    %% Model Conversion - SEPARATE SCRIPT
    subgraph "Phase 4: Model Conversion"
        E1[convert_models.py<br/>ðŸ“± Deployment Formats]
        E2[ONNX Model]
        E3[CoreML Model]
        E4[TensorFlow Lite]
    end
    
    %% Connections
    A1 --> B1
    A2 --> B1
    A3 --> B1
    B1 --> B2
    B1 --> B3
    B1 --> B4
    
    B2 --> D1
    B3 --> D1
    B4 --> D1
    C1 --> D1
    C2 --> D1
    
    D1 --> D2
    D1 --> D3
    D1 --> D4
    D1 --> D5
    
    D4 --> E1
    E1 --> E2
    E1 --> E3
    E1 --> E4
    
    %% Styling
    classDef bootstrap fill:#e1f5fe
    classDef infrastructure fill:#f3e5f5
    classDef training fill:#e8f5e8
    classDef conversion fill:#fff3e0
    classDef remove fill:#ffebee,stroke:#f44336,stroke-width:3px,stroke-dasharray: 5 5
    
    class B1,B2,B3,B4 bootstrap
    class C1,C2 infrastructure
    class D1,D2,D3,D4,D5 training
    class E1,E2,E3,E4 conversion