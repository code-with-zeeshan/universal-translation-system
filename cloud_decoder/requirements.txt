# cloud_decoder/requirements.txt

# Core dependencies
numpy>=1.24.0,<2.0.0
msgpack>=1.0.5
lz4>=4.3.2

# FastAPI and server
fastapi>=0.104.0
uvicorn[standard]>=0.24.0
gunicorn>=21.2.0
python-multipart>=0.0.6
httpx>=0.25.0

# PyTorch (CPU version - GPU version installed separately in Dockerfile)
# torch>=2.1.0
# For local development without GPU:
# torch>=2.1.0+cpu -f https://download.pytorch.org/whl/torch_stable.html

# Async support
aiofiles>=23.2.0
asyncio>=3.4.3

# Monitoring and logging
prometheus-client>=0.18.0
python-json-logger>=2.0.7

# Compression
python-lz4>=1.2.0

# Utilities
tqdm>=4.66.0
psutil>=5.9.5
tenacity>=8.2.3

# Type hints
typing-extensions>=4.8.0
pydantic>=2.4.0

# For health checks and testing
httpx>=0.25.0
pytest>=7.4.0
pytest-asyncio>=0.21.0

# Performance optimization
uvloop>=0.19.0
orjson>=3.9.10

# Optional: For distributed tracing
# opentelemetry-api>=1.20.0
# opentelemetry-sdk>=1.20.0
# opentelemetry-instrumentation-fastapi>=0.41b0

# Optional: For model optimization
# onnx>=1.15.0
# onnxruntime-gpu>=1.16.0  # For GPU inference

# Development dependencies (optional)
# black>=23.10.0
# isort>=5.12.0
# pylint>=3.0.0
# mypy>=1.6.0