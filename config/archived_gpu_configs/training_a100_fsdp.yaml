# config/training_a100_fsdp.yaml
# Inherits from the base A100 config but overrides for large scale
_base_: 'training_a100.yaml'

training:
  use_fsdp: true
  sharding_strategy: "HYBRID_SHARD" # Better for large models
  mixed_precision: true
  dtype: "bfloat16"
  compile_model: true
  compile_mode: "max-autotune"
  gradient_checkpointing: true
  batch_size: 128 # Larger batch size for powerful GPUs